# config.yml

model_type:
  translate
# mdoel args
model:        
    tokenizer_name_or_path: "BAAI/bge-reranker-base"
    vecab_dim: 768
    n_head: 16
    ffn_hidden: 3072
    n_layers: 6
    drop_prob: 0.1
    max_seq_len: 1024
    device: cuda   

# trainning args
traininng:
  batch_size: 1               
  epochs: 1000          
  learning_rate: 0.0001   
  optimizer: AdamW              
  weight_decay: 0.01
  clip_max_norm: 0.5
  factor: 0.3
  patience: 15         
  device: cuda

dataset_type:
  translate
dataset:
  train_data_path: "wmt17_train/train.jsonl"       
  test_data_path: "wmt17_train/test.jsonl"       
  valid_data_path: "wmt17_train/vaild.jsonl"       
  max_padding_length: 512


logging:
  log_interval: 100             
  save_dir: "./saved_model/translate"   
