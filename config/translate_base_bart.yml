# config.yml

# mdoel args
model_type:
  translate_from_pretrained
model:        
    pretrain_model_name_or_path: "facebook/mbart-large-50-many-to-many-mmt"
    src_lang: en_XX
    tgt_lang: zh_CN
    device: cuda   

# trainning args
traininng:
  batch_size: 2              
  epochs: 1000          
  learning_rate: 0.00002   
  optimizer: AdamW              
  weight_decay: 0.1
  clip_max_norm: 0.5
  factor: 0.3
  patience: 15         
  device: cuda


dataset_type:
  translate
dataset:
  train_data_path: "wmt17_train/train.jsonl"       
  test_data_path: "wmt17_train/test.jsonl"       
  valid_data_path: "wmt17_train/valid.jsonl"       
  max_padding_length: 512


logging:
  log_interval: 100             
  save_dir: "./saved_model/translate_from_pretrained"   
